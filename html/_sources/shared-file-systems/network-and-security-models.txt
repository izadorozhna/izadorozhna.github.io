.. _shared_fs_network&security_models:

===========================
Network and security models
===========================
There are big number of the share drives created by different vendors in the
Shared File Systems Storage service. Each share driver is a python class that
can be set for the back end (an instance of the manila-share service) and run
in the back end to manage the share operations (some operations are
vendor-specific). Each share driver supports one or more driver modes:
single-svm and multi-svm, but the administrator chooses which mode is used by
specifying it in the configuration file :file:`manila.conf`.

The multi-svm mode can be configured with flat network, or with segmented
network. This depends on the network provider.

It is possible to have separate drivers for different modes on the same
hardware if that makes sense. Depending on which mode is chosen, the
administrator needs to provide additional details in the configuration file as
well.

.. _single-svm-vs-multi-svm:

Single-svm vs multi-svm back ends
---------------------------------
Each share driver supports one or more driver modes to configure the back ends.
Initially there are 2 driver modes for the back ends:

* **Single SVM**
* **Multi SVM**

The configuration option in :file:`manila.conf` file that set the single-svm or
multi-svm mode is ``driver_handles_share_servers`` option, that defines the
driver mode for share storage life cycle management:

+------------+---------------------------------------+------------------------+
| Mode       | Config option                         |  Description           |
+============+=======================================+========================+
| Single-svm | driver_handles_share_servers = False  | An administrator       |
|            |                                       | rather than a share    |
|            |                                       | driver manages the     |
|            |                                       | bare metal storage     |
|            |                                       | with some net          |
|            |                                       | interface instead of   |
|            |                                       | the presence of the    |
|            |                                       | share servers.         |
+------------+---------------------------------------+------------------------+
| Multi-svm  | driver_handles_share_servers = True   | The share driver       |
|            |                                       | creates the share      |
|            |                                       | server and manages,    |
|            |                                       | or handles, the share  |
|            |                                       | server life cycle.     |
+------------+---------------------------------------+------------------------+

This is the share types which have the extra specifications that help scheduler
to filter back ends and choose the appropriate back end for the user that
requested to create a share. The required extra boolean specification for each
share type is ``driver_handles_share_servers``. As an administrator, you can
create the share types with the specifications you need. For details of
managing the share types and configuration the back ends, see `Share types
<http://docs.openstack.org/admin-guide-cloud/shared_file_systems_share_
types.html>`_ and `Multi-storage configuration <http://docs.openstack.org/
admin-guide-cloud/shared_file_systems_multi_backend.html>`_ documentation.

.. glossary::

Single-svm
    In this mode, drivers have basically no network requirements whatsoever.
    It's assumed that the actual storage controller(s) being managed by the
    driver has all of the network interfaces it's going to need. The Shared
    File Systems service will expect the driver to provision shares directly
    without creating any share server beforehand. The Shared File Systems
    service will assume that the network interfaces through which any shares
    are exported are already reachable by all tenants. This mode corresponds to
    what some existing drivers are already doing, but it makes explicit the
    choice for the administrator. In this mode, share networks are not really
    needed at share creation time, and are ignored.

Multi-svm
    In this mode, the driver is able to create SVMs and join them to an
    existing network. For providing every new SVM, the drivers can expect from
    the Shared File Systems service a subnet definition and the IP addresses.

In the **single-svm** mode the share driver does not handles the storage life
cycle. An administrator should care about the storage, network interfaces and
so on. In this mode an administrator can have the storage(s) as a host which
exports the shares. The main characteristic of this mode is that the storage
is not handled by the Shared File Systems service. The users in tenants share
one common network, host, processor, and network pipe. The users can hinder
each other if there is no correct balancing adjustment. In the public clouds it
is possible to use all the network pipe some client.

Unlike the single-svm mode, in the **multi-svm** mode the users have the share
network and the share server that is created for each share network. Thus all
users have separate CPU, amount of CPU time, network, capacity and throughput.

You also can configure the
:ref:`security services <shared_fs_security_services>` in both single-svm and
multi-svm back-end modes. But with single-svm back-end mode, an administrator
should set the desired authentication services manually on the host. And in the
multi-svm mode of the back end The Shared File Systems service can be
configured automatically with any of existing security services supported by
the share driver.

Flat vs segmented networking
----------------------------
The Shared File Systems Storage service allows to work with different types of
a network:

* ``local``
* ``flat``
* ``GRE``
* ``VLAN``
* ``VXLAN``

.. note::
    The Shared File Systems service is just keeping the information about the
    networks, and the real networks are available due to the network provider.
    In OpenStack it can be nova or neutron services, but actually the Shared
    File Systems service can work even out of OpenStack. That is is due to the
    ``StandaloneNetworkPlugin`` that can be used with any network platform and
    does not require some specific network services in OpenStack like Neutron
    or Nova. You can set the network parameters in its configuration file.

In the :ref:`multi-svm <single-svm-vs-multi-svm>` back-end mode the share
driver creates and manages the share server for each share network.This mode
can be divided on two variations:

* Flat network multi SVM
* Segmented network multi SVM

Initially, while creating the share network, you can set up either a neutron
network and subnet or a nova network. To create the share network, the Shared
File Systems service needs the IDs of the neutron network and subnet, or just
nova network ID to set up for share server. The third approach is to configure
the networking without Nova and Neutron services. The
``StandaloneNetworkPlugin`` can be used with any network platform. You can set
the network parameters in its configuration file.

After the share network is created, the Shared File Systems service retrieves
the network information determined by the network provider: the segmentation
identifier if the network uses segmentation (for VLAN, this is a value from 1
to 4094; for VXLAN, this is a value from 1 to 16777215; for GRE, this is a
value from 1 to 4294967295), the network type (which can be VLAN, VXLAN, GRE,
flat, or local), the IP version of the network, and the IP block in Classless
Inter-Domain Routing (CIDR) notation from which to allocate the network.

Below you can see the comparison of the flat network multi SVM with segmented
network multi SVM.

**Flat network multi SVM**

This mode, some storage controllers can create SVMs but due to various
limitations of the physical/logical network all of the SVMs have to be on a
flat network. In this mode, the share driver needs something to provision IP
addresses for the SVMs, but the IPs all come out of the same subnet and that
subnet itself it assumed to be reachable by all tenants.

The share drivers in the mode can expect Manila to provide a subnet definition
(network address, mask, broadcast, and gateway addresses) and the specific IP
address(es) for each share server during creation.

In this mode, the :ref:`security service part <shared_fs_security_services>` of
the share networks is important because it allows tenants to specify security
requirements such as AD/LDAP domains or a Kerberos realm. The subnet part of
the share network is not really that useful. The Shared File Systems service
assumes that any hosts referred to in the security service are reachable from
the subnet where the SVM is created, which limits the situations where this
mode makes sense.

**Segmented network multi SVM**

In this mode, the share driver is able to create SVMs and join them to an
existing segmented network.

At a minimum, the share drivers expect the Shared File systems to provide for
every new SVM: a subnet definition (network address, mask, broadcast, and
gateway) and list of IP addresses; a segmentation type (VLAN, VXLAN, GRE, etc);
and a segmentation ID and any other info relevant to the segmentation type.

.. note::
    The share drivers may not support every type of segmentation, for details
    see the specification for each driver.

The security aspects of the configured networks depends on the configuration
itself and the network provider.

.. _shared_fs_network_plugins:

Network plug-ins
----------------

The Shared File Systems service architecture defines an abstraction layer for
network resource provisioning and allowing administrators to choose from a
different options for how network resources are assigned to their tenantsâ€™
networked storage. There are a set of network plug-ins that provide a variety
of integration approaches with the network services that are available with
OpenStack.

The network plug-ins allow to use any nova or neutron functions and
configurations, for example, you can use any network segmentation that Neutron
supports, or you can use flat Nova networks or VLAN-segmented Nova networks, or
you can use the plugin for specifying networks independently from OpenStack
networking services. For more information of how to use different network
plug-ins, see `Shared File Systems service Network plug-ins <http://docs.
openstack.org/admin-guide-cloud/shared_file_systems_network_plugins.html#
network-plug-ins>`_. The security in using different network plug-ins depends
on the specific network configuration.
